{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvL27OJhZz6G",
        "outputId": "88c54f91-8673-4c7c-c0ee-51f2ca95a19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-fidelity\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (4.67.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.46)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.49.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torch-fidelity) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torch-fidelity) (3.0.3)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: torch-fidelity\n",
            "Successfully installed torch-fidelity-0.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch-fidelity wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import time\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CXLBnoBgz_D",
        "outputId": "8c9a28a2-a150-40b4-82fc-340f33bcd464"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    # dataset\n",
        "    \"dataset\": \"CIFAR-10\",\n",
        "    \"image_size\": 32,\n",
        "    \"channels\": 3,\n",
        "\n",
        "    # model\n",
        "    \"model\": \"beta-VAE\",\n",
        "    \"latent_dim\": 128,\n",
        "    \"encoder_channels\": [32, 64, 128],\n",
        "\n",
        "    # training\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 30,\n",
        "    \"lr\": 2e-4,\n",
        "    \"recon_loss\": \"MSE\",\n",
        "    \"beta\": 0.25,\n",
        "\n",
        "    # evaluation\n",
        "    \"fid_every\": 5,\n",
        "    \"fid_samples\": 1000,\n",
        "    \"kid_subset_size\": 300,\n",
        "\n",
        "    # logging\n",
        "    \"log_images\": True,\n",
        "    \"num_log_images\": 16,\n",
        "}"
      ],
      "metadata": {
        "id": "saNGbj4vOj77"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = (\n",
        "    f\"VAE_beta{config['beta']}_\"\n",
        "    f\"z{config['latent_dim']}_\"\n",
        "    f\"lr{config['lr']}\"\n",
        ")\n",
        "\n",
        "wandb.init(\n",
        "    project=\"generative-modeling-on-cifar-10\",\n",
        "    name=run_name,\n",
        "    config=config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "umaLdGgfOnfI",
        "outputId": "b7e34fa3-55bf-482f-8f08-c890197328b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgioeba\u001b[0m (\u001b[33mgioeba-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260127_094137-8we65n1f</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10/runs/8we65n1f' target=\"_blank\">VAE_beta0.25_z128_lr0.0002</a></strong> to <a href='https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10' target=\"_blank\">https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10/runs/8we65n1f' target=\"_blank\">https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10/runs/8we65n1f</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gioeba-free-university-of-tbilisi-/generative-modeling-on-cifar-10/runs/8we65n1f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f0657baed80>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_folder = \"/tmp/cifar10_real\"\n",
        "gen_folder = \"/tmp/cifar10_gen\"\n",
        "os.makedirs(real_folder, exist_ok=True)\n",
        "os.makedirs(gen_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "LnLBvp5Zi9VF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor()\n",
        ")\n",
        "\n",
        "if len(os.listdir(real_folder)) == 0:\n",
        "    print(\"Saving real CIFAR-10 images...\")\n",
        "    for i in tqdm(range(10000)):\n",
        "        img, _ = real_dataset[i]\n",
        "        vutils.save_image(img, os.path.join(real_folder, f\"real_{i}.png\"))\n",
        "else:\n",
        "    print(\"Real images already exist, skipping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bCLUZDjjBOn",
        "outputId": "645e646a-242b-49bb-a74a-60fa8a689172"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:09<00:00, 18.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving real CIFAR-10 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:09<00:00, 1043.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=False,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "3CELyrCEg2ib"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        ch = config[\"encoder_channels\"]\n",
        "        latent_dim = config[\"latent_dim\"]\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, ch[0], 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(ch[0], ch[1], 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(ch[1], ch[2], 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(ch[2]*4*4, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(ch[2]*4*4, latent_dim)\n",
        "        self.fc_dec = nn.Linear(latent_dim, ch[2]*4*4)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(ch[2], ch[1], 4, 2, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(ch[1], ch[0], 4, 2, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(ch[0], 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x).view(x.size(0), -1)\n",
        "        return self.fc_mu(h), self.fc_logvar(h)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.fc_dec(z).view(-1, config[\"encoder_channels\"][-1], 4, 4)\n",
        "        return self.decoder(h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "metadata": {
        "id": "xuDAhfUgg57V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(x_hat, x, mu, logvar):\n",
        "    recon = F.mse_loss(x_hat, x, reduction=\"sum\")\n",
        "    kl = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon + kl"
      ],
      "metadata": {
        "id": "4i5HLs95hAGH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(config).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "wandb.watch(model, log=\"gradients\", log_freq=500)\n",
        "\n",
        "fid_scores = []\n",
        "kid_scores = []\n",
        "epochs_list = []\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_recon = 0.0\n",
        "    total_kl = 0.0\n",
        "    latent_mu_mean = 0.0\n",
        "    latent_mu_std = 0.0\n",
        "\n",
        "    for x, _ in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
        "        x = x.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_hat, mu, logvar = model(x)\n",
        "\n",
        "        recon = F.mse_loss(x_hat, x, reduction=\"sum\")\n",
        "        kl = -0.5 * torch.sum(\n",
        "            1 + logvar - mu.pow(2) - logvar.exp()\n",
        "        )\n",
        "\n",
        "        loss = recon + config[\"beta\"] * kl\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_recon += recon.item()\n",
        "        total_kl += kl.item()\n",
        "\n",
        "        latent_mu_mean += mu.mean().item()\n",
        "        latent_mu_std += mu.std().item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_set)\n",
        "    avg_recon = total_recon / len(train_set)\n",
        "    avg_kl = total_kl / len(train_set)\n",
        "    latent_mu_mean /= len(train_loader)\n",
        "    latent_mu_std /= len(train_loader)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train/total_loss\": avg_loss,\n",
        "        \"train/recon_loss\": avg_recon,\n",
        "        \"train/kl_loss\": avg_kl,\n",
        "        \"latent/mu_mean\": latent_mu_mean,\n",
        "        \"latent/mu_std\": latent_mu_std,\n",
        "        \"time/epoch_sec\": epoch_time,\n",
        "        \"beta\": config[\"beta\"],\n",
        "    })\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch} | \"\n",
        "        f\"Loss: {avg_loss:.4f} | \"\n",
        "        f\"Recon: {avg_recon:.4f} | \"\n",
        "        f\"KL: {avg_kl:.4f}\"\n",
        "    )\n",
        "\n",
        "    if epoch % config[\"fid_every\"] == 0:\n",
        "        model.eval()\n",
        "\n",
        "        if os.path.exists(gen_folder):\n",
        "            shutil.rmtree(gen_folder)\n",
        "        os.makedirs(gen_folder, exist_ok=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n_samples = config[\"fid_samples\"]\n",
        "            batch_size = 64\n",
        "            idx = 0\n",
        "\n",
        "            for _ in range(n_samples // batch_size):\n",
        "                z = torch.randn(\n",
        "                    batch_size,\n",
        "                    config[\"latent_dim\"],\n",
        "                    device=device\n",
        "                )\n",
        "\n",
        "                imgs = model.decode(z)\n",
        "                imgs = (imgs + 1) / 2\n",
        "                imgs = imgs.clamp(0, 1)\n",
        "\n",
        "                for j in range(imgs.size(0)):\n",
        "                    vutils.save_image(\n",
        "                        imgs[j],\n",
        "                        os.path.join(gen_folder, f\"{idx}.png\")\n",
        "                    )\n",
        "                    idx += 1\n",
        "\n",
        "        metrics = calculate_metrics(\n",
        "            input1=gen_folder,\n",
        "            input2=real_folder,\n",
        "            fid=True,\n",
        "            kid=True,\n",
        "            kid_subset_size=config[\"kid_subset_size\"]\n",
        "        )\n",
        "\n",
        "        fid = metrics[\"frechet_inception_distance\"]\n",
        "        kid = metrics[\"kernel_inception_distance_mean\"]\n",
        "\n",
        "        fid_scores.append(fid)\n",
        "        kid_scores.append(kid)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        wandb.log({\n",
        "            \"metrics/FID\": fid,\n",
        "            \"metrics/KID\": kid,\n",
        "        })\n",
        "\n",
        "        if config[\"log_images\"]:\n",
        "            with torch.no_grad():\n",
        "                z = torch.randn(\n",
        "                    config[\"num_log_images\"],\n",
        "                    config[\"latent_dim\"],\n",
        "                    device=device\n",
        "                )\n",
        "                samples = model.decode(z)\n",
        "                samples = (samples + 1) / 2\n",
        "                samples = samples.clamp(0, 1)\n",
        "\n",
        "            grid = vutils.make_grid(samples, nrow=4)\n",
        "            wandb.log({\n",
        "                \"samples\": wandb.Image(\n",
        "                    grid.permute(1, 2, 0).cpu().numpy(),\n",
        "                    caption=f\"Epoch {epoch}\"\n",
        "                )\n",
        "            })\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch} | \"\n",
        "            f\"FID: {fid:.2f} | \"\n",
        "            f\"KID: {kid:.5f}\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFm22-q8hFK7",
        "outputId": "9d78fa96-73e5-47c9-ea41-f011381fa8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 391/391 [00:17<00:00, 22.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 352.5398 | Recon: 330.7979 | KL: 86.9676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 391/391 [00:15<00:00, 24.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Loss: 201.9501 | Recon: 171.5416 | KL: 121.6337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 391/391 [00:15<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Loss: 174.8085 | Recon: 143.4349 | KL: 125.4946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 391/391 [00:14<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Loss: 160.0682 | Recon: 128.3359 | KL: 126.9292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 391/391 [00:14<00:00, 27.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Loss: 148.5971 | Recon: 116.0759 | KL: 130.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n",
            "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 267MB/s]\n",
            "Extracting features from input1\n",
            "Looking for samples non-recursivelty in \"/tmp/cifar10_gen\" with extensions png,jpg,jpeg\n",
            "Found 960 samples\n",
            "/usr/local/lib/python3.12/dist-packages/torch_fidelity/datasets.py:16: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(height, width, 3)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Processing samples\n",
            "Extracting features from input2\n",
            "Looking for samples non-recursivelty in \"/tmp/cifar10_real\" with extensions png,jpg,jpeg\n",
            "Found 10000 samples\n",
            "Processing samples\n",
            "Frechet Inception Distance: 250.81035202984603\n",
            "Kernel Inception Distance: 0.25072011470794675 ± 0.005563293500981493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | FID: 250.81 | KID: 0.25072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 391/391 [00:16<00:00, 23.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Loss: 141.1249 | Recon: 107.9993 | KL: 132.5023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 391/391 [00:15<00:00, 24.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | Loss: 136.0787 | Recon: 102.4557 | KL: 134.4922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 391/391 [00:15<00:00, 25.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 | Loss: 132.2259 | Recon: 98.2369 | KL: 135.9559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 391/391 [00:15<00:00, 25.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 | Loss: 129.0459 | Recon: 94.5739 | KL: 137.8877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 391/391 [00:15<00:00, 25.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Loss: 126.4948 | Recon: 91.6288 | KL: 139.4640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n",
            "Extracting features from input1\n",
            "Looking for samples non-recursivelty in \"/tmp/cifar10_gen\" with extensions png,jpg,jpeg\n",
            "Found 960 samples\n",
            "Processing samples\n",
            "Extracting features from input2\n",
            "Looking for samples non-recursivelty in \"/tmp/cifar10_real\" with extensions png,jpg,jpeg\n",
            "Found 10000 samples\n",
            "Processing samples:  15%|█▍        | 1472/10000 [00:06<00:33, 256.75samples/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_list, fid_scores, marker=\"o\")\n",
        "plt.title(\"FID over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"FID\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_list, kid_scores, marker=\"o\")\n",
        "plt.title(\"KID over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"KID\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "wandb.log({\n",
        "    \"FID_KID_curves\": wandb.Image(plt.gcf())\n",
        "})"
      ],
      "metadata": {
        "id": "ir_oioR2hT9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(16, config[\"latent_dim\"]).to(device)\n",
        "    samples = model.decode(z)\n",
        "    samples = (samples + 1) / 2\n",
        "    samples = samples.clamp(0, 1)\n",
        "\n",
        "grid = vutils.make_grid(samples, nrow=4)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Final VAE Samples\")\n",
        "plt.show()\n",
        "\n",
        "wandb.log({\n",
        "    \"final_samples\": wandb.Image(\n",
        "        grid.permute(1, 2, 0).cpu().numpy(),\n",
        "        caption=\"Final VAE Samples\"\n",
        "    )\n",
        "})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "MLy07GWGhWDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}